{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MegaMillionsExtractionAPI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nJdI4wnkpk3tqnP4xSKng37a9v_txT__",
      "authorship_tag": "ABX9TyOWdFErYNUImucZHQmUb6eG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kspohn903/MegaMillions_ML_RidgeRegression_Predictor/blob/main/MegaMillionsExtractionAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GruR3fOKg8PC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5962b6f-c332-42b9-ab09-3c2cd219ab65"
      },
      "source": [
        "# #PACKAGE IMPORTS/DOWNLOADS/FETCH COMMANDS FOR ENVIRONMENT \n",
        "\n",
        "!pip install -q timestring \n",
        "!pip install -q datetime \n",
        "!pip install -q data\n",
        "!pip install -q api-client # Alternate data collection protocols... \n",
        "!pip install -q requests_html # Web scraper packages\n",
        "!pip install -q bs4 # unneeded if you have a source of api/ data to feed in... else web scrape.\n",
        "!pip install -q urllib3 # making sure that OSI L6 stuff can read in surface html and parse web documentation/ documents\n",
        "!pip install -q nltk # data processing, sentiment analysis \n",
        "!pip install -q pandas # data frames, reading in data, blah...\n",
        "!pip install -q numpy # same as scipy. Manipulating tensor metrics, learning, adapting, etc.\n",
        "!pip install -q imgaug # Necessary if reading in specific google colab/ tensorflow,\n",
        "!pip install -q folium # usually used with image classifiers\n",
        "!pip install -q datascience # tensorflow of choice... manipulating for regressional analytics \n",
        "!pip install -q scipy\n",
        "# !pip install -q google-cloud \n",
        "!pip install -q rauth\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# # !pip install --upgrade numpy # Alternative Updater to numpy... \n",
        "# If not Tensorflow or conflicts in package resolution, then this one...\n",
        "\n",
        "# ARE YOU ON THE TRAIN??? ... THEN GET ON THE TRAIN!!! Edwarrrrrd!!!! \n",
        "# File reading likeness... as STRING_IO.(parserToken)\n",
        "from google.colab import drive, files, auth\n",
        "drive.mount('/content/drive', force_remount=True) # mounted / forcibly-remounted\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for timestring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 51 kB 275 kB/s \n",
            "\u001b[K     |████████████████████████████████| 251 kB 9.2 MB/s \n",
            "\u001b[?25h  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for api-client (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 47.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.7 MB/s \n",
            "\u001b[?25h  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.2 MB/s \n",
            "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rauth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.2 MB/s \n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P10yz5Tw5UXU"
      },
      "source": [
        "\n",
        "import pandas as pd, numpy as np, sys \n",
        "\n",
        "# # dateutil, secrets act as secondary date parser iff datetime fails or threadback issues of parsing dates...\n",
        "# # optional args/ imports: ----------------------------------------------------\n",
        "# import dateutil, secrets, bs4 as soup, urllib3, gzip, tenacity \n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "import json, requests, csv, traceback as tb, seaborn as sns, scipy as sci\n",
        "import matplotlib.pyplot as plt, math, gzip, os, io, re, matplotlib.pylab as pl \n",
        "import matplotlib.transforms as mt, datetime, time, gc\n",
        "\n",
        "# from apiclient import (APIClient, paginated, exceptions, retry_request,\n",
        "#                HeaderAuthentication, JsonResponseHandler, JsonRequestFormatter, endpoint) \n",
        "\n",
        "import sklearn\n",
        "from datetime import timedelta # any other methods...\n",
        "# from apiclient.retrying import retry_if_api_request_error\n",
        "from matplotlib.transforms import offset_copy \n",
        "from google.colab import files # Stealing/ Uploading/ Downloading to RAM files from my drive... \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from io import StringIO\n",
        "\n",
        "# # File reading, analytics, dataframe manipulation en masse, datetime checks, garbage thread collection RAM/ NVRAM\n",
        "# # Regex checking, files collected (requests/ urllib3), sys for filepath oauth checks... file dumps/reading\n",
        "\n",
        "# # error thread checking, graphical displays, data analytics, plotting s***, you know\n",
        "# # Everything here is super kosher... \n",
        "# from bs4 import BeautifulSoup as bs\n",
        "from matplotlib.font_manager import FontProperties\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDj_Aqf8g8y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76453587-915f-455e-e9cc-6c52aa83dab7"
      },
      "source": [
        "#Derive_API_JSON_FROM_RAPIDAPI_REQUESTS.py\n",
        "try:\n",
        "    # Derive Mega Millions Numerical String Data of Winners from \n",
        "    today = datetime.datetime.now() # Current day: e.g. (MM-DD-YYYY = 06-11-2021)\n",
        "    responseMsg = input(\"What day are you starting? (e.g. 12/31/2019, 10/31/2017); Format: MM/DD/YYYY\")\n",
        "    dateInput = responseMsg.split(\"/\")\n",
        "    dateInput = [int(el) for el in dateInput]\n",
        "    while dateInput[0] not in [i for i in range(1,13,1)] or (\n",
        "          dateInput[1] not in [i for i in range(1,32,1)]) or ( \n",
        "          dateInput[2] not in [yr for yr in range(2017, today.year + 1, 1)]) or (\n",
        "          re.match(\"/[(\\d{1-2})(-/)(\\d{1-2})(-/)(\\d{2-4})]/g\", responseMsg) ):\n",
        "          \n",
        "          responseMsg = input(\"What day are you starting? (e.g. 12/31/2019, 10/31/2017); Format: MM/DD/YYYY\")\n",
        "          dateInput = responseMsg.split(\"/\")\n",
        "          dateInput = [int(el) for el in dateInput] \n",
        "\n",
        "    firstDay = datetime.datetime(year = dateInput[2], month = dateInput[0], day = dateInput[1])\n",
        "    print(f\"firstDay is {firstDay}\\n\")\n",
        "    # Oct 31, 2017; 2020 data is set to Dec, 31, 2019 in the above format\n",
        "    # \n",
        "    # Beyond this point back, number winning schemas are inconsistent and \n",
        "    # remain pairwise within certain time periods/ intervals  \n",
        "    \n",
        "    fDayString = firstDay.strftime(\"%m %d %Y\")\n",
        "    fDayString = fDayString.replace(\" \",\"_\")\n",
        "    \n",
        "    todayString = today.strftime(\"%m %d %Y\")\n",
        "    todayString = todayString.replace(\" \", \"_\")\n",
        "    \n",
        "    print(f\"fDayString: {fDayString}\\ntodayString: {todayString}\\n\")\n",
        "    \n",
        "    # Modify to closest Tuesday/Thursday, based on bi-weekly draws approx. Midnight that day...\n",
        "    \n",
        "    yearA = firstDay.year # MM/DD/YYYY\n",
        "    print(f\"yearA is {yearA}\\n\")\n",
        "    superDirName = 'drive/MyDrive/CSV_Files/Mega Millions/'\n",
        "    filePathName = '{}MegaBall_Schema_{}_as_of_{}.csv'.format(superDirName,yearA,todayString) \n",
        "    \n",
        "    # Manually download from the NY State / NYC municipality dataset. Then, \n",
        "    # Append any subsequent data from future dates... append all 5 data tables up to speed ...\n",
        "    # Then download it... \n",
        "    # Now from Excel Google Sheets, read in data as normal\n",
        "\n",
        "    #  print(f\"Before reading in from file path, \\ \n",
        "    #  Steve-Bot is testing file read in from os, and validity of dataframe...\\n\")\n",
        "    \n",
        "    dfMegaMillions = pd.read_csv(filePathName,header=0)\n",
        "    print(\"dfMegaMillions is successfully being read in...\\n\")\n",
        "    \n",
        "    print(\"---------- The column headers ------------\\n\")\n",
        "    headerColumns = list(dfMegaMillions.columns.values)\n",
        "    print(f\"Header Columns: {headerColumns}\\n\")\n",
        "\n",
        "    drawingDate = dfMegaMillions[headerColumns[0]].values\n",
        "    firstNum = dfMegaMillions[headerColumns[1]].values\n",
        "    secondNum = dfMegaMillions[headerColumns[2]].values\n",
        "    thirdNum = dfMegaMillions[headerColumns[3]].values\n",
        "    fourthNum = dfMegaMillions[headerColumns[4]].values\n",
        "    fifthNum = dfMegaMillions[headerColumns[5]].values\n",
        "    megaBall = dfMegaMillions[headerColumns[6]].values\n",
        "    megaplier = dfMegaMillions[headerColumns[7]].values\n",
        "\n",
        "    lenCheck = [len(drawingDate) == el for el in [len(firstNum), len(secondNum), \n",
        "                                                 len(thirdNum), len(fourthNum), \n",
        "                                                 len(fifthNum), len(megaBall)] ]\n",
        "\n",
        "    print(f\"arrLenCheck:{lenCheck}, allSameSizeVectors: {False not in lenCheck}\\n\")\n",
        "   \n",
        "    #  data = [drawingDate,firstNumber, secondNumber, thirdNumber, \n",
        "    #          fourthNumber, fifthNumber, megaBall, megaplier ]\n",
        "\n",
        "    megaHeadersJSON = [ \"First_Number\", \"Second_Number\", \"Third_Number\", \n",
        "                        \"Fourth_Number\", \"Fifth_Number\", \"Mega_Ball\", \"Megaplier\" ]\n",
        "    \n",
        "    #  print(f\"DrawingDate:\\n{drawingDate}\\nFirstNumber:\\n{firstNum}\\n\")\n",
        "    #  print(f\"SecondNumber:\\n{secondNum}\\nThirdNumber:\\n{thirdNum}\\n\")\n",
        "    #  print(f\"FourthNumber:\\n{fourthNum}\\nFifthNumber:\\n{fifthNum}\\n\")\n",
        "    #  print(f\"MegaBall:\\n{megaBall}\\nMegaplier:\\n{megaplier}\\n\")\n",
        "\n",
        "    jsonFreq = { # By definition first 5 1-70, last one 1-25\n",
        "    1 : {\"{}\".format(i): 0 for i in range(1,71,1)}, # 1-70; Ball 1\n",
        "    2 : {\"{}\".format(i): 0 for i in range(1,71,1)}, # 1-70; Ball 2\n",
        "    3 : {\"{}\".format(i): 0 for i in range(1,71,1)},  # 1-70; Ball 3 \n",
        "    4 : {\"{}\".format(i): 0 for i in range(1,71,1)},  # 1-70; Ball 4                                          \n",
        "    5 : {\"{}\".format(i): 0 for i in range(1,71,1)}, # 1-70; Ball 5\n",
        "    6 : {\"{}\".format(i): 0 for i in range(1,26,1)}, # 1-25; Mega Ball \n",
        "    } # append all elements into each respective json\n",
        "   \n",
        "    print(f\"Before populating by frequencies:\\n{jsonFreq}\\n\")\n",
        "    for i in range(0, len(firstNum), 1): #dnc about the megaplier\n",
        "        jsonFreq[1][\"{}\".format(firstNum[i])] += 1\n",
        "        jsonFreq[2][\"{}\".format(secondNum[i])] += 1      \n",
        "        jsonFreq[3][\"{}\".format(thirdNum[i])] += 1\n",
        "        jsonFreq[4][\"{}\".format(fourthNum[i])] += 1\n",
        "        jsonFreq[5][\"{}\".format(fifthNum[i])] += 1\n",
        "        jsonFreq[6][\"{}\".format(megaBall[i])] += 1\n",
        "        \n",
        "        #  print(f\"Populating Frequency Iteration no. {i+1}: (\")\n",
        "        #  print(f\"json1={jsonFreq[1]},json2={jsonFreq[2]},json3={jsonFreq[3]}\", end=',') \n",
        "        # print(f\"json4={jsonFreq[4]}, json5={jsonFreq[5]}, json6={jsonFreq[6]})\", end = \"\\n\")\n",
        "    print(f\"After: {jsonFreq}\\n\")\n",
        "    \n",
        "    #  t1, t2, t3, t4, t5, t6 = 0, 0, 0, 0, 0, 0\n",
        "    k1 = list(jsonFreq[1].keys())\n",
        "    k2 = list(jsonFreq[2].keys())\n",
        "    k3 = list(jsonFreq[3].keys())\n",
        "    k4 = list(jsonFreq[4].keys())\n",
        "    k5 = list(jsonFreq[5].keys())\n",
        "    k6 = list(jsonFreq[6].keys())\n",
        "    #  print(f\"k1: {k1}\\nk2: {k2}\\nk3: {k3}\\nk4: {k4}\\nk5: {k5}\\nk6: {k6}\\n\")\n",
        "   \n",
        "    v1 = list(jsonFreq[1].values()) # Frequencies of 1-70 for Nums. 1-5\n",
        "    v2 = list(jsonFreq[2].values())\n",
        "    v3 = list(jsonFreq[3].values())\n",
        "    v4 = list(jsonFreq[4].values()) \n",
        "    v5 = list(jsonFreq[5].values())\n",
        "    v6 = list(jsonFreq[6].values()) # MegaBall Frequencies 1-25 \n",
        "    #  print(f\"v1: {v1}\\nv2: {v2}\\nv3: {v3}\\nv4: {v4}\\nv5: {v5}\\nv6: {v6}\\n\")\n",
        "   \n",
        "    vTot = [int(el) for el in v1]\n",
        "    t1, t2, t3, t4, t5, t6 = 0, 0, 0, 0, 0, 0\n",
        "    for i in range(0,len(v1), 1):\n",
        "       e1 = int(vTot[i])\n",
        "       e2 = int(v2[i])\n",
        "       e3 = int(v3[i])\n",
        "       e4 = int(v4[i])\n",
        "       e5 = int(v5[i])\n",
        "       \n",
        "       #  print(f\"(e1={e1}, e2={e2}, e3={e3}, e4={e4}, e5={e5})\\n\")\n",
        "       sumFreq = int (e2+e3+e4+e5)\n",
        "\n",
        "       #  print(f\"Prior to appending sumFreq: (lTot: {int(vTot[i])}, sumFreq:{sumFreq})\\n\")\n",
        "       t1 += int(v1[i])\n",
        "       t2 += int(v2[i])\n",
        "       t3 += int(v3[i])\n",
        "       t4 += int(v4[i])\n",
        "       t5 += int(v5[i])\n",
        "       vTot[i] += int(sumFreq)\n",
        "       \n",
        "       #  print(f\"Total Frequency for Digit No.{i+1} (for Balls 1-5), is {int(vTot[i])}.\\n\")\n",
        "       #  print(f\"Stats for iteration No. = {i+1}: (t1={t1}, t2={t2}, t3={t3}, t4={t4}, t5={t5})\\n\")\n",
        "       \n",
        "       print(f\"Final Stats: (t1:{t1}, t2:{t2}, t3:{t3}, t4:{t4}, t5:{t5})\\n\")\n",
        "       print(f\"After total appendation, vTot: {vTot}\\n\")\n",
        "   \n",
        "       maxNoDraws = t1\n",
        "       print(f\"maxNoDraws: {maxNoDraws}\\n\")\n",
        "   \n",
        "       jsonFreq[7] = {\"{}\".format(i+1): int(vTot[i]) for i in range(0,len(vTot),1)}\n",
        "       print(f\"Checking jsonFreq[7] patch: {jsonFreq[7]}\\n\")\n",
        "       df_1_5 = pd.DataFrame(data={ \"First_Number\": jsonFreq[1], \n",
        "                                    \"Second_Number\": jsonFreq[2],\n",
        "                                    \"Third_Number\": jsonFreq[3],\n",
        "                                    \"Fourth_Number\": jsonFreq[4],\n",
        "                                    \"Fifth_Number\": jsonFreq[5],\n",
        "                                    \"Total\": jsonFreq[7] \n",
        "                                  } )\n",
        "       #  # weighted stat. avg. of total draws, i.e. max. no draws from dt A to dt B (today).\n",
        "       df_1_5[\"Prob_Ball1\"] = round(df_1_5[\"First_Number\"]/maxNoDraws, 6) \n",
        "       df_1_5[\"Prob_Ball2\"] = round(df_1_5[\"Second_Number\"]/maxNoDraws, 6)\n",
        "       df_1_5[\"Prob_Ball3\"] = round(df_1_5[\"Third_Number\"]/maxNoDraws, 6)\n",
        "       df_1_5[\"Prob_Ball4\"] = round(df_1_5[\"Fourth_Number\"]/maxNoDraws, 6)\n",
        "       df_1_5[\"Prob_Ball5\"] = round(df_1_5[\"Fifth_Number\"]/maxNoDraws, 6)\n",
        "       df_1_5[\"Prob_Total\"] = round(df_1_5[\"Total\"]/maxNoDraws, 6)\n",
        "\n",
        "       df_1_5.sort_values(by=['Prob_Total','Total'], inplace=True, ascending=False)\n",
        "       #  print(f\"{df_1_5['Prob_Total']}\\n{df_1_5['Prob_Ball1']}\\n{df_1_5['Prob_Ball2']}\\n{df_1_5['Prob_Ball3']}\\n{df_1_5['Prob_Ball4']}\\n{df_1_5['Prob_Ball5']}\\n\")\n",
        "       df_6 = pd.DataFrame(data={\"Mega_Ball\": jsonFreq[6] })\n",
        "       \n",
        "       df_6[\"Prob_Mega_Ball\"] = round(df_6[\"Mega_Ball\"]/maxNoDraws, 6)\n",
        "       df_6.sort_values(by=['Prob_Mega_Ball','Mega_Ball'], inplace=True, ascending=False)\n",
        "       #  print(f\"df_1_5:\\n{df_1_5}\\ndf_6:\\n{df_6}\\nProb_Total:\\n{df_1_5['Prob_Total']}\\n\")\n",
        "\n",
        "       df_1_5.to_csv('{}Mega_Millions_Ball5_Stats_{}_as_of_{}.csv'.format(superDirName, yearA, todayString), index = True) # yearNo: e.g. {2020,2021}, v. overall\n",
        "       df_6.to_csv('{}Mega_Millions_Mega_Ball_Stats_{}_as_of_{}.csv'.format(superDirName, yearA, todayString), index=True)\n",
        "       print(f\"dataframes have been saved to misc. csv files...\\n For later extraction, analytics, and likelihood estimators...\\nShutting down...\\n\")\n",
        "   \n",
        "except IOError: \n",
        "       print(f\"Failure to properly close/read file (IO). Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except EOFError:\n",
        "       print(f\"Failure to properly read/parse file properly or has reached EOF.Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except IndentationError: \n",
        "       print(f\"Failure to properly indent. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except ImportError: \n",
        "       print(f\"Import has failed. Please check imports and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Exception: \n",
        "       print(f\"General Exception has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Error: \n",
        "       print(f\"General Error has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What day are you starting? (e.g. 12/31/2019, 10/31/2017); Format: MM/DD/YYYY10/31/2017\n",
            "firstDay is 2017-10-31 00:00:00\n",
            "\n",
            "fDayString: 10_31_2017\n",
            "todayString: 02_15_2022\n",
            "\n",
            "yearA is 2017\n",
            "\n",
            "dfMegaMillions is successfully being read in...\n",
            "\n",
            "---------- The column headers ------------\n",
            "\n",
            "Header Columns: ['DrawingDate', 'FirstNumber', 'SecondNumber', 'ThirdNumber', 'FourthNumber', 'FifthNumber', 'MegaBall', 'Megaplier', 'NumberSet']\n",
            "\n",
            "arrLenCheck:[True, True, True, True, True, True], allSameSizeVectors: True\n",
            "\n",
            "Before populating by frequencies:\n",
            "{1: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, '37': 0, '38': 0, '39': 0, '40': 0, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 2: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, '37': 0, '38': 0, '39': 0, '40': 0, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 3: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, '37': 0, '38': 0, '39': 0, '40': 0, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 4: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, '37': 0, '38': 0, '39': 0, '40': 0, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 5: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0, '26': 0, '27': 0, '28': 0, '29': 0, '30': 0, '31': 0, '32': 0, '33': 0, '34': 0, '35': 0, '36': 0, '37': 0, '38': 0, '39': 0, '40': 0, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 6: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 0, '19': 0, '20': 0, '21': 0, '22': 0, '23': 0, '24': 0, '25': 0}}\n",
            "\n",
            "After: {1: {'1': 32, '2': 24, '3': 34, '4': 34, '5': 17, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 2: {'1': 0, '2': 2, '3': 4, '4': 5, '5': 6, '6': 9, '7': 7, '8': 10, '9': 9, '10': 16, '11': 13, '12': 12, '13': 11, '14': 20, '15': 16, '16': 15, '17': 19, '18': 9, '19': 13, '20': 15, '21': 5, '22': 18, '23': 9, '24': 18, '25': 13, '26': 13, '27': 8, '28': 10, '29': 8, '30': 11, '31': 11, '32': 11, '33': 11, '34': 9, '35': 8, '36': 7, '37': 9, '38': 10, '39': 1, '40': 3, '41': 6, '42': 3, '43': 7, '44': 5, '45': 6, '46': 1, '47': 4, '48': 2, '49': 1, '50': 1, '51': 0, '52': 2, '53': 2, '54': 2, '55': 0, '56': 0, '57': 0, '58': 1, '59': 1, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}, 3: {'1': 0, '2': 0, '3': 0, '4': 1, '5': 1, '6': 0, '7': 0, '8': 1, '9': 2, '10': 3, '11': 4, '12': 3, '13': 8, '14': 6, '15': 5, '16': 6, '17': 7, '18': 7, '19': 7, '20': 10, '21': 7, '22': 5, '23': 10, '24': 9, '25': 14, '26': 15, '27': 12, '28': 11, '29': 11, '30': 14, '31': 20, '32': 12, '33': 8, '34': 11, '35': 7, '36': 9, '37': 17, '38': 8, '39': 18, '40': 14, '41': 9, '42': 11, '43': 9, '44': 17, '45': 5, '46': 9, '47': 10, '48': 10, '49': 4, '50': 5, '51': 7, '52': 3, '53': 10, '54': 2, '55': 4, '56': 8, '57': 4, '58': 7, '59': 0, '60': 3, '61': 3, '62': 1, '63': 2, '64': 0, '65': 1, '66': 1, '67': 0, '68': 0, '69': 0, '70': 0}, 4: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 1, '9': 0, '10': 1, '11': 0, '12': 1, '13': 0, '14': 0, '15': 0, '16': 1, '17': 3, '18': 4, '19': 4, '20': 2, '21': 4, '22': 3, '23': 2, '24': 4, '25': 2, '26': 4, '27': 7, '28': 5, '29': 3, '30': 5, '31': 9, '32': 6, '33': 7, '34': 9, '35': 9, '36': 5, '37': 4, '38': 13, '39': 7, '40': 9, '41': 10, '42': 18, '43': 15, '44': 12, '45': 6, '46': 18, '47': 9, '48': 18, '49': 13, '50': 9, '51': 9, '52': 16, '53': 12, '54': 17, '55': 7, '56': 14, '57': 10, '58': 13, '59': 13, '60': 9, '61': 15, '62': 13, '63': 7, '64': 8, '65': 7, '66': 5, '67': 4, '68': 5, '69': 2, '70': 0}, 5: {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0, '10': 0, '11': 0, '12': 0, '13': 0, '14': 0, '15': 0, '16': 0, '17': 0, '18': 1, '19': 0, '20': 0, '21': 0, '22': 1, '23': 1, '24': 0, '25': 1, '26': 0, '27': 2, '28': 1, '29': 2, '30': 1, '31': 2, '32': 0, '33': 1, '34': 3, '35': 0, '36': 1, '37': 2, '38': 4, '39': 5, '40': 2, '41': 2, '42': 5, '43': 8, '44': 4, '45': 7, '46': 8, '47': 4, '48': 10, '49': 6, '50': 8, '51': 3, '52': 10, '53': 11, '54': 8, '55': 13, '56': 14, '57': 18, '58': 17, '59': 18, '60': 17, '61': 12, '62': 25, '63': 16, '64': 26, '65': 17, '66': 22, '67': 23, '68': 28, '69': 23, '70': 35}, 6: {'1': 18, '2': 15, '3': 14, '4': 21, '5': 15, '6': 16, '7': 13, '8': 13, '9': 23, '10': 22, '11': 24, '12': 16, '13': 20, '14': 18, '15': 17, '16': 16, '17': 18, '18': 19, '19': 20, '20': 17, '21': 14, '22': 26, '23': 14, '24': 20, '25': 19}}\n",
            "\n",
            "Final Stats: (t1:32, t2:0, t3:0, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 24, 34, 34, 17, 19, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 32\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 24, '3': 34, '4': 34, '5': 17, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:56, t2:2, t3:0, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 34, 34, 17, 19, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 56\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 34, '4': 34, '5': 17, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:90, t2:6, t3:0, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 34, 17, 19, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 90\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 34, '5': 17, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:124, t2:11, t3:1, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 17, 19, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 124\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 17, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:141, t2:17, t3:2, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 19, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 141\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 19, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:160, t2:26, t3:2, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 28, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 160\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 28, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:188, t2:33, t3:2, t4:0, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 26, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 188\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 26, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:214, t2:43, t3:3, t4:1, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 18, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 214\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 18, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:232, t2:52, t3:5, t4:1, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 26, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 232\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 26, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:258, t2:68, t3:8, t4:2, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 19, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 258\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 19, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:277, t2:81, t3:12, t4:2, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 12, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 277\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 12, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:289, t2:93, t3:15, t4:3, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 10, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 289\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 10, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:299, t2:104, t3:23, t4:3, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 16, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 299\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 16, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:315, t2:124, t3:29, t4:3, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 12, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 315\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 12, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:327, t2:140, t3:34, t4:3, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 10, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 327\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 10, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:337, t2:155, t3:40, t4:4, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 17, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 337\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 17, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:354, t2:174, t3:47, t4:7, t5:0)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 9, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 354\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 9, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:363, t2:183, t3:54, t4:11, t5:1)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 6, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 363\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 6, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:369, t2:196, t3:61, t4:15, t5:1)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 9, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 369\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 9, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:378, t2:211, t3:71, t4:17, t5:1)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 8, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 378\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 8, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:386, t2:216, t3:78, t4:21, t5:1)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 5, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 386\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 5, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:391, t2:234, t3:83, t4:24, t5:2)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 5, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 391\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 5, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:396, t2:243, t3:93, t4:26, t5:3)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 5, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 396\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 5, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:401, t2:261, t3:102, t4:30, t5:3)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 6, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 401\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 6, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:407, t2:274, t3:116, t4:32, t5:4)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 2, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 407\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 2, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:409, t2:287, t3:131, t4:36, t5:4)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 4, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 409\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 4, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:413, t2:295, t3:143, t4:43, t5:6)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 7, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 413\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 7, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:420, t2:305, t3:154, t4:48, t5:7)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 7, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 420\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 7, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:427, t2:313, t3:165, t4:51, t5:9)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 2, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 427\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 2, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:429, t2:324, t3:179, t4:56, t5:10)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 1, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 429\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 1, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:430, t2:335, t3:199, t4:65, t5:12)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 2, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 430\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 2, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:432, t2:346, t3:211, t4:71, t5:12)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 3, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 432\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 3, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:435, t2:357, t3:219, t4:78, t5:13)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 5, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 435\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 5, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:440, t2:366, t3:230, t4:87, t5:16)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 440\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 0, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:440, t2:374, t3:237, t4:96, t5:16)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 440\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 2, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:442, t2:381, t3:246, t4:101, t5:17)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 442\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 1, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:443, t2:390, t3:263, t4:105, t5:19)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 443\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 1, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:444, t2:400, t3:271, t4:118, t5:23)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 444\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 1, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:445, t2:401, t3:289, t4:125, t5:28)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 445\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 1, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:446, t2:404, t3:303, t4:134, t5:30)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 446\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 1, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:447, t2:410, t3:312, t4:144, t5:32)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 447\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 0, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:447, t2:413, t3:323, t4:162, t5:37)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 447\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 0, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:447, t2:420, t3:332, t4:177, t5:45)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 447\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 0, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:447, t2:425, t3:349, t4:189, t5:49)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 447\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 0, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:447, t2:431, t3:354, t4:195, t5:56)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 447\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 1, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:432, t3:363, t4:213, t5:64)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 0, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:436, t3:373, t4:222, t5:68)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 0, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:438, t3:383, t4:240, t5:78)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 0, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:439, t3:387, t4:253, t5:84)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 0, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:440, t3:392, t4:262, t5:92)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 0, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:440, t3:399, t4:271, t5:95)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 0, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:442, t3:402, t4:287, t5:105)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 0, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:444, t3:412, t4:299, t5:116)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 0, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:446, t3:414, t4:316, t5:124)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 0, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:446, t3:418, t4:323, t5:137)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 0, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:446, t3:426, t4:337, t5:151)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 0, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:446, t3:430, t4:347, t5:169)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 0, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:447, t3:437, t4:360, t5:186)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 0, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:437, t4:373, t5:204)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 0, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:440, t4:382, t5:221)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 0, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:443, t4:397, t5:233)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 0, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:444, t4:410, t5:258)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 0, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:446, t4:417, t5:274)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 0, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:446, t4:425, t5:300)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 0, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:447, t4:432, t5:317)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 0, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 0, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:448, t4:437, t5:339)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 28, 0, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 28, '67': 0, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:448, t4:441, t5:362)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 28, 27, 0, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 28, '67': 27, '68': 0, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:448, t4:446, t5:390)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 28, 27, 33, 0, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 28, '67': 27, '68': 33, '69': 0, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:448, t4:448, t5:413)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 28, 27, 33, 25, 0]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 28, '67': 27, '68': 33, '69': 25, '70': 0}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n",
            "Final Stats: (t1:448, t2:448, t3:448, t4:448, t5:448)\n",
            "\n",
            "After total appendation, vTot: [32, 26, 38, 40, 24, 28, 35, 38, 29, 46, 36, 28, 29, 42, 33, 32, 46, 30, 30, 36, 24, 32, 27, 36, 36, 34, 33, 34, 31, 33, 43, 31, 30, 37, 24, 24, 33, 36, 32, 29, 28, 37, 39, 38, 24, 37, 27, 40, 24, 23, 19, 31, 35, 29, 24, 36, 32, 38, 32, 29, 30, 39, 25, 34, 25, 28, 27, 33, 25, 35]\n",
            "\n",
            "maxNoDraws: 448\n",
            "\n",
            "Checking jsonFreq[7] patch: {'1': 32, '2': 26, '3': 38, '4': 40, '5': 24, '6': 28, '7': 35, '8': 38, '9': 29, '10': 46, '11': 36, '12': 28, '13': 29, '14': 42, '15': 33, '16': 32, '17': 46, '18': 30, '19': 30, '20': 36, '21': 24, '22': 32, '23': 27, '24': 36, '25': 36, '26': 34, '27': 33, '28': 34, '29': 31, '30': 33, '31': 43, '32': 31, '33': 30, '34': 37, '35': 24, '36': 24, '37': 33, '38': 36, '39': 32, '40': 29, '41': 28, '42': 37, '43': 39, '44': 38, '45': 24, '46': 37, '47': 27, '48': 40, '49': 24, '50': 23, '51': 19, '52': 31, '53': 35, '54': 29, '55': 24, '56': 36, '57': 32, '58': 38, '59': 32, '60': 29, '61': 30, '62': 39, '63': 25, '64': 34, '65': 25, '66': 28, '67': 27, '68': 33, '69': 25, '70': 35}\n",
            "\n",
            "dataframes have been saved to misc. csv files...\n",
            " For later extraction, analytics, and likelihood estimators...\n",
            "Shutting down...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dORXhV7prtfr"
      },
      "source": [
        "# Prev. File Name: MEGAMILLIONS_Stat_Pictographic.py\n",
        "# split dataset in train and testing set   \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try: \n",
        "    #yearA, responseMsg/todayStr ... No longer needed... Input already validated.\n",
        "    \n",
        "    filePathName1 = '{}Mega_Millions_Ball5_Stats_{}_as_of_{}.csv'.format(superDirName, yearA, todayString)\n",
        "    filePathName2 = '{}Mega_Millions_Mega_Ball_Stats_{}_as_of_{}.csv'.format(superDirName, yearA, todayString)\n",
        "    # print(f\"Before reading in from file path, Steve-Bot is testing file read in from os, and validity of dataframe...\\n\")\n",
        "    \n",
        "    dfMegaMillions_Ball5 = pd.read_csv(filePathName1, header=0, nrows=30) # \n",
        "    # print(\"dfMegaMillions_Ball5 is successfully being read in...\\n\")\n",
        "    \n",
        "    headerColumnsBall5 = dfMegaMillions_Ball5.columns.values\n",
        "    print(f\"The Header Columns Ball5: {headerColumnsBall5}\\n\")\n",
        "    \n",
        "    datasetBall5 = dfMegaMillions_Ball5.values\n",
        "    dfMegaMillions_MegaBall = pd.read_csv(filePathName2,header=0,nrows=15) \n",
        "    datasetMB = dfMegaMillions_MegaBall.values\n",
        "    # print(\"dfMegaMillions_MegaBall is successfully being read in...\\n\")\n",
        "    \n",
        "    headerColumnsMegaBall = dfMegaMillions_MegaBall.columns.values\n",
        "    print(f\"The Header Columns MegaBall: {headerColumnsMegaBall}\\n\")\n",
        "    \n",
        "    # Values 5 Ball, megaBall: headerColumnsMegaBall[0], headerColumnsBall5[0]\n",
        "    # 5 Ball: [Value, First_Number, Second_Number, Third_Number, Fourth_Number, Fifth_Number, Total,\n",
        "    # Prob_Ball1, Prob_Ball2, Prob_Ball3, Prob_Ball4, Prob_Ball5, Prob_Total]\n",
        "    # Mega Ball: [Ball Value, Freq_Mega_Ball, Prob_Mega_Ball]\n",
        "    \n",
        "    # Assuming values in numB5, numMB are dependent on probability of regressional predictions...\n",
        "    # Where the probability of a number is treated as independent, non-categorical\n",
        "    xB5 = dfMegaMillions_Ball5[headerColumnsBall5[0]] # Ball Value for B5\n",
        "    xMB = dfMegaMillions_MegaBall[headerColumnsMegaBall[0]] # Ball Value for MB\n",
        "    print(f\"(xB5: {xB5.values}\\nxMB: {xMB.values})\\n\")\n",
        "    \n",
        "    yB1 = dfMegaMillions_Ball5[headerColumnsBall5[-6]] # Prob_Ball1 Column Data\n",
        "    yB2 = dfMegaMillions_Ball5[headerColumnsBall5[-5]] # Prob_Ball2 ...\n",
        "    yB3 = dfMegaMillions_Ball5[headerColumnsBall5[-4]] # Prob_Ball3 ...\n",
        "    yB4 = dfMegaMillions_Ball5[headerColumnsBall5[-3]] # Prob_Ball4 ...\n",
        "    yB5 = dfMegaMillions_Ball5[headerColumnsBall5[-2]] # Prob_Ball5 ...\n",
        "    yBTot = dfMegaMillions_Ball5[headerColumnsBall5[-1]] # Prob_Total ...\n",
        "    \n",
        "    # yB = [yB1, yB2, yB3, yB4, yB5, yBTot]\n",
        "    # Prob Ball_5: {Prob_Ball{i+1}, Prob_Total}\n",
        "    \n",
        "    yMB = dfMegaMillions_MegaBall[headerColumnsMegaBall[2]]\n",
        "    print(f\"(yB1:{yB1.values}\\nyB2:{yB2.values}\\nyB3:{yB3.values}\\nyB4:{yB4.values}\\nyB5:{yB5.values}\\nyBTot:{yBTot.values})\\n\")\n",
        "    \n",
        "    # Creating figure & saving relevant graphics data    \n",
        "    # EX: ---------------------------------------------------------------------\n",
        "    # Assuming that len(x)==len(y) for datasets \n",
        "    # reg = linear_model.LinearRegression()\n",
        "    # modelB5 = reg.fit(xB5, yB5)\n",
        "    # modelMB = reg.fit(xMB, yMB)\n",
        "    \n",
        "    # reg2 = linear_model.LinearRegression() \n",
        "    # reg2.fit(x_poly, y)\n",
        "\n",
        "    # plt.title(\"Polynomial Regression\")\n",
        "    # plt.xlabel(\"Position Level\")\n",
        "    # plt.ylabel(\"Salary\")\n",
        "    # plt.scatter(x, y, color ='red')\n",
        "    # plt.plot(x, lin_reg2.predict(poly_reg.fit_transform(x)), color = 'blue')\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    nSubgroupsBall5 = 70\n",
        "    nBall5 = 5\n",
        "\n",
        "    totNoEl = 6\n",
        "    count = 0\n",
        "    bar_width = 0.30\n",
        "    opacity = 0.80\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(10,10))  \n",
        "    # bar_pos_B5 = np.arange(nSubgroupsBall5)  \n",
        "\n",
        "    bChartB5_1 = fig1.bar(xB5 + count*(totNoEl)*bar_width, yB1, bar_width,\n",
        "    alpha=opacity, color='orange', label='Ball {}'.format(count+1))\n",
        "    count += 1\n",
        "    \n",
        "    bChartB5_2 = plt.bar(xB5 + count*(totNoEl)*bar_width, yB2, bar_width,\n",
        "    alpha=opacity, color='blue', label='Ball {}'.format(count+1))\n",
        "    count += 1\n",
        "\n",
        "    bChartB5_3 = plt.bar(xB5 + count*(totNoEl)*bar_width, yB3, bar_width,\n",
        "    alpha=opacity, color='purple', label='Ball {}'.format(count+1))\n",
        "    count += 1\n",
        "    \n",
        "    bChartB5_4 = plt.bar(xB5 + count*(totNoEl)*bar_width, yB4, bar_width,\n",
        "    alpha=opacity, color='green', label='Ball {}'.format(count+1))\n",
        "    count += 1\n",
        "    \n",
        "    bChartB5_5 = plt.bar(xB5 +count*(totNoEl)*bar_width, yB5, bar_width,\n",
        "    alpha=opacity, color='red', label='Ball {}'.format(count+1))\n",
        "    count += 1\n",
        "    \n",
        "    bChartB5_Tot = plt.bar(xB5 + count*(totNoEl)*bar_width, yBTot, bar_width,\n",
        "    alpha=opacity, color='#A14C75', label='Ball Total')\n",
        "    count += 1\n",
        "\n",
        "    # x_train_raw_B5, x_test_raw_B5, y_train_B5, y_test_B5 = train_test_split(\n",
        "    # # Scrape from B5 \n",
        "        \n",
        "    # ) # this function will split train and test data set in 75%-25% respectively\n",
        "    # vector = TfidfVectorizer()\n",
        "    # x_train_B5 = vector.fit_transform(x_train_raw)\n",
        "    # x_test_B5 = vector.transform(x_test_raw)\n",
        "    # model = linear_model.LinearRegression()\n",
        "    # model.fit(xB5, yBTot)\n",
        "    # probPredictor = model.predict()\n",
        "    # r_square_value=model.score(np.array(x_test).reshape(-1,1),np.array(y_test).reshape(-1,1))\n",
        "    # print(f'r-square value from Linear Regression: {r_square_value}\\n')\n",
        "     \n",
        "    # Model 1: Ball5 Values based on B5 data xB5, yB5 = P(xB5 for all XB5 (subset member of xB5; ball 1, 2, ..., ) in xB5) \n",
        "    plt.xlabel('Ball Value')\n",
        "    plt.ylabel('P(Ball)')\n",
        "    plt.title('Bar Chart of Ball 5 Value v. P(Ball 5)')\n",
        "    # print(f\"Testing if tuple arr concatonator works for str bar chart grouped by stat frequency ***BEFORE***...\\n\")\n",
        "    plt.xticks(xB5 + totNoEl*bar_width, tuple([str(ball) for ball in xB5]) )\n",
        "    # print(f\"Testing if tuple arr concatonator works for str bar chart grouped by stat frequency ***AFTER***...\\n\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('MegaMillions_Ball5_BarChartPlot_{}_{}.png'.format(\n",
        "        yearA,datetime.datetime.now().strftime(\"%Y %m %d\").replace(\" \",\"-\") ) )\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot 2: Mega Ball Distinct plot by horizontal and by sorting order... May create subgrouping axes to \n",
        "    # predict in sorted fashion, but documentation I read is insufficient to complete that procedure.\n",
        "    fig2, ax2 = plt.subplots(figsize=(8,8))\n",
        "    bChartMB = plt.bar(xMB, yMB, bar_width, alpha=opacity, color='purple', label='Mega Ball')\n",
        "    plt.xlabel('Ball Value')\n",
        "    plt.ylabel('P(Mega Ball)')\n",
        "    plt.title('Bar Chart of Ball 5 Value v. P(Mega Ball)')\n",
        "    # print(f\"Testing if tuple arr concatonator works for str bar chart grouped by stat frequency ***BEFORE***...\\n\")\n",
        "    plt.xticks(xMB + bar_width, tuple([str(ball) for ball in xMB]) )\n",
        "    # print(f\"Testing if tuple arr concatonator works for str bar chart grouped by stat frequency ***AFTER***...\\n\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('MegaMillions_MegaBall_BarChartPlot_{}_{}.png'.format(\n",
        "        yearA,datetime.datetime.now().strftime(\"%Y %m %d\").replace(\" \",\"-\") ) )\n",
        "    plt.show()\n",
        "    \n",
        "    # regB1=LinearRegression()  \n",
        "    # regB1.fit(numB5,p1B5)  \n",
        "    # y_pre = reg.predict(X_test) \n",
        "\n",
        "    ### Intended for Regression _Prediction, either RidgeRegression using lineardense \n",
        "        # as matrix fodder data, and trainsets for linear predictors,\n",
        "        # based on KNN's, but I'm not skilled enough to use a KNN of that \n",
        "        # regression predictor form... Not competent enough, yet.  \n",
        "\n",
        "except IOError: \n",
        "       print(f\"Failure to properly close/read file (IO). Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except EOFError:\n",
        "       print(f\"Failure to properly read/parse file properly or has reached EOF.Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except IndentationError: \n",
        "       print(f\"Failure to properly indent. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except ImportError: \n",
        "       print(f\"Import has failed. Please check imports and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Exception: \n",
        "       print(f\"General Exception has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Error: \n",
        "       print(f\"General Error has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFzEwlmPvZv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e85189-24dd-44fd-99e4-c9a19d796419"
      },
      "source": [
        "# Previous Super File Name: ML_MEGAMILLIONS_WHEEL_GENERATOR.ipynb\n",
        "try:\n",
        "    # todayFileStr = datetime.datetime.today().strftime(\"%m %d %Y\").replace(\" \",\"_\")\n",
        "    filePathName1 = 'drive/MyDrive/CSV_Files/Mega_Millions_Ball5_Stats_{}_as_of_{}.csv'.format(yearA, todayString)\n",
        "    filePathName2 = 'drive/MyDrive/CSV_Files/Mega_Millions_Mega_Ball_Stats_{}_as_of_{}.csv'.format(yearA, todayString)\n",
        "    # print(f\"Before reading in from file path, Steve-Bot is testing file read in from os, and validity of dataframe...\\n\")\n",
        "    \n",
        "    dfMegaMillions_Ball5 = pd.read_csv(filePathName1,header=0)\n",
        "    print(\"dfMegaMillions_Ball5 is successfully being read in...\\n\")\n",
        "    headerColumnsBall5 = dfMegaMillions_Ball5.columns.values\n",
        "    # print(f\"The Header Columns Ball5: {headerColumnsBall5}\\n\")\n",
        "    dfMegaMillions_MegaBall = pd.read_csv(filePathName2,header=0)\n",
        "    print(\"dfMegaMillions_MegaBall is successfully being read in...\\n\")\n",
        "\n",
        "    headerColumnsMegaBall = dfMegaMillions_MegaBall.columns.values\n",
        "    print(f\"The Header Columns MegaBall: {headerColumnsMegaBall}\\n\")\n",
        "    \n",
        "    # print(f\"dfs's:\\nBall5\\n{dfMegaMillions_Ball5}\\nMegaBall\\n{dfMegaMillions_MegaBall}\\n\")   \n",
        "    \n",
        "    # Verify that each Prob_Mega_Ball for df2, Prob_Total from df1 yield 1 for each column set...\n",
        "    # Attempt to justify that total probability for each Ball No. \n",
        "    megaBallNos = dfMegaMillions_MegaBall[headerColumnsMegaBall[0]].values\n",
        "    probTotal_Vector = dfMegaMillions_Ball5[\"Prob_Total\"].values\n",
        "    probAvgTotal_Vector = [el/5 for el in probTotal_Vector]\n",
        "    \n",
        "    # print(f\"probAvgTotal_Vector: {probAvgTotal_Vector}\\n\")\n",
        "    probMegaBall_Vector = dfMegaMillions_MegaBall[\"Prob_Mega_Ball\"].values\n",
        "\n",
        "    t1, t2 = 0, 0\n",
        "    # print(f\"probTotal_Vector:\\n {probTotal_Vector}\\nprobMegaBall_Vector:\\n {probMegaBall_Vector}\\n\") \n",
        "    \n",
        "    for i in range(0,len(probTotal_Vector), 1):\n",
        "        t1 += probTotal_Vector[i]    \n",
        "    t1 /= 5\n",
        "    \n",
        "    for j in range(0, len(probMegaBall_Vector), 1):\n",
        "        t2 += probMegaBall_Vector[j]\n",
        "    \n",
        "    print(f\"[b5,mB]: [{t1},{t2}]\\n\")  \n",
        "    [pBall1_Vector, pBall2_Vector, pBall3_Vector, pBall4_Vector, pBall5_Vector, ball5Nos] = [\n",
        "    dfMegaMillions_Ball5[\"Prob_Ball1\"].values, dfMegaMillions_Ball5[\"Prob_Ball2\"].values,\n",
        "    dfMegaMillions_Ball5[\"Prob_Ball3\"].values, dfMegaMillions_Ball5[\"Prob_Ball4\"].values,\n",
        "    dfMegaMillions_Ball5[\"Prob_Ball5\"].values, dfMegaMillions_Ball5[headerColumnsBall5[0]].values]\n",
        "    \n",
        "    p1,p2,p3,p4,p5 = 0,0,0,0,0\n",
        "    for k in range(0,len(pBall1_Vector),1):\n",
        "        p1 += pBall1_Vector[k]\n",
        "        p2 += pBall2_Vector[k]\n",
        "        p3 += pBall3_Vector[k]\n",
        "        p4 += pBall4_Vector[k]\n",
        "        p5 += pBall5_Vector[k]   \n",
        "\n",
        "    megaBallNos = megaBallNos[0:10]\n",
        "    ball5Nos = ball5Nos[0:50] # 6 * (noWheelStructsDesired=; nWSD <= len(vector) && %6==0)-1\n",
        "    \n",
        "    # print(f\"The top 6 values for ball5Nos and megaBallNos are ({ball5Nos}, {megaBallNos})\\n\")\n",
        "    # print(f\"[len(ball5Nos),len(megaBallNos)] = [{len(ball5Nos)},{len(megaBallNos)}]\\n\")    \n",
        "    \n",
        "    # ball5Nos = sorted(ball5Nos)\n",
        "    # megaBallNos = sorted(megaBallNos)\n",
        "    # print(f\"sorted BallNos= (ball5Nos,megaBallNos): ({ball5Nos, megaBallNos})\\n\")\n",
        "    \n",
        "    # print(f\"pBall1: {pBall1_Vector}\\npBall2: {pBall2_Vector}\\npBall3: {pBall3_Vector}\\npBall4: {pBall4_Vector}\\npBall5: {pBall5_Vector}\\n\")\n",
        "    # print(f\"probTotal_Vector:\\n {probTotal_Vector}\\nprobMegaBall_Vector:\\n {probMegaBall_Vector}\\n\") \n",
        "    \n",
        "    # print(f\"Hot Numbers by 5 Ball/ Mega Ball, respectively...\\nBall5:\\n{ball5Nos}\\nMega Ball:\\n{megaBallNos}\\n\")\n",
        "    \n",
        "    predicted_avg = (p1+p2+p3+p4+p5)/5\n",
        "    print(f\"[p1,p2,p3,p4,p5,predictedAvg]: [{p1}, {p2}, {p3}, {p4}, {p5}, {predicted_avg}]\\n\")\n",
        "    \n",
        "    # Missing probability of at most, +0.06937394247, throughout df[...]_Ball5\n",
        "    # So, ~100% of all probabilities accounted for... Some lost in rounding, I guess\n",
        "    # **gaining**, on avg., 0.018849e-2% per entry... \n",
        "    # Dunno if that's true or not, but I'll assume yes...\n",
        "\n",
        "    wheel_data_trainset_ABSPATHNAME= '{}MEGA_MILLIONS_WHEEL_TRAINSET_{}_{}.csv'.format(\n",
        "        superDirName,yearA,todayString)\n",
        "    train_set_wheel_numerical = open(wheel_data_trainset_ABSPATHNAME,mode=\"w+\")\n",
        "    for i in range(1,7,1): # Writing Headers Properly... n%6 == 0 1st iteration only, NOT to 12 mod 6\n",
        "        if i%6 != 0: # 0-5 \n",
        "           train_set_wheel_numerical.write(\"Ball {}, \".format(i%6))\n",
        "        else: \n",
        "           train_set_wheel_numerical.write(\"Mega Ball\\n\")\n",
        "\n",
        "    wheelSchema = { \"Set 1\": [1,2,3,4,5,6,7,8,9,10,11,12],\n",
        "                    \"Set 2\":[1,3,5,7,9,11,2,4,6,8,10,12], \n",
        "                    \"Set 3\":[1,2,3,10,11,12,4,5,6,7,8,9],  \n",
        "                    \"Set 4\":[1,2,3,7,8,9,4,5,6,10,11,12] }\n",
        "    noWheelSets = 4\n",
        "    for n in range(0, int(len(ball5Nos)/10), 1):\n",
        "        # print(f\"Iteration no. for n: {n+1}\\n\")\n",
        "        for j in range(0, int(len(megaBallNos)/5),1):\n",
        "            b1_1 = ball5Nos[10*n]\n",
        "            b2_1 = ball5Nos[10*n+1]\n",
        "            b3_1 = ball5Nos[10*n+2]\n",
        "            b4_1 = ball5Nos[10*n+3]\n",
        "            b5_1 = ball5Nos[10*n+4]\n",
        "            mB1 = megaBallNos[j]\n",
        "            b1_2 = ball5Nos[10*n+5]\n",
        "            b2_2 = ball5Nos[10*n+6]\n",
        "            b3_2 = ball5Nos[10*n+7]\n",
        "            b4_2 = ball5Nos[10*n+8]\n",
        "            b5_2 = ball5Nos[10*n+9]\n",
        "            mB2 = megaBallNos[j+1]\n",
        "            wheelSet = [b1_1, b2_1, b3_1, b4_1, b5_1, mB1,\n",
        "                        b1_2, b2_2, b3_2, b4_2, b5_2, mB2]\n",
        "\n",
        "            for m in range(1,noWheelSets+1,1):\n",
        "                # print(f\"Set No. {m} \")\n",
        "                setNo = wheelSchema[\"Set {}\".format(m)]\n",
        "                for k in range(0, len(setNo),1):\n",
        "                    if (k+1)%6 != 0:\n",
        "                      #  print(f\"{wheelSet[setNo[k]-1]} \")\n",
        "                      train_set_wheel_numerical.write(\"{}, \".format(wheelSet[setNo[k]-1]))\n",
        "                    else: \n",
        "                      #  print(f\"{wheelSet[setNo[k]-1]}\\n\")\n",
        "                      mB = [mB1,mB2]\n",
        "                      train_set_wheel_numerical.write(\"{}\\n\".format(wheelSet[setNo[k]-1] if wheelSet[setNo[k]-1] < 26 else mB[j]))\n",
        "                # print(f\"Set No. {m} Printed successfully...\\n\")\n",
        "            # print(f\"Internal iteration no., j is {j+1}\\n\")\n",
        "        # print(f\"End of iteration no. {n+1}...\\n\")\n",
        "        print(f\"Garbage Dump! .. Please stand *urp* back...\\n\")\n",
        "        gc.collect()\n",
        "        # print(f\"Forcibly reallocating memory at end of loop iteration no. {n+1}\\n\")     \n",
        "    print(f\"Closing train_set_wheel_numerical...\\n\")\n",
        "    train_set_wheel_numerical.close()\n",
        "\n",
        "except IOError: \n",
        "       print(f\"Failure to properly close/read file (IO). Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except EOFError:\n",
        "       print(f\"Failure to properly read/parse file properly or has reached EOF.Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except IndentationError: \n",
        "       print(f\"Failure to properly indent. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except ImportError: \n",
        "       print(f\"Import has failed. Please check imports and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Exception: \n",
        "       print(f\"General Exception has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()\n",
        "except Error: \n",
        "       print(f\"General Error has occurred. Please check stack trace and try again.\\n\")\n",
        "       tb.print_exc()   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure to properly close/read file (IO). Please check stack trace and try again.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-edcb6bb2ab02>\", line 9, in <module>\n",
            "    dfMegaMillions_Ball5 = pd.read_csv(filePathName1,header=0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
            "    self._engine = self._make_engine(self.engine)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
            "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
            "    self._open_handles(src, kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\", line 229, in _open_handles\n",
            "    errors=kwds.get(\"encoding_errors\", \"strict\"),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\", line 707, in get_handle\n",
            "    newline=\"\",\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'drive/MyDrive/CSV_Files/Mega_Millions_Ball5_Stats_2017_as_of_02_15_2022.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prize Validator\n",
        "# Check your Mega Millions/ PowerBall numbers!\n",
        "\n",
        "# orginal checker app code created by Brandon I.\n",
        "# URL Brandon I: https://github.com/Und3rf10w/Powerball-results-checker\n",
        "\n",
        "import sys, io, json, pandas as pd, numpy as np\n",
        "import scipy as sci\n",
        "wheelFilePath = \"{}MEGA_MILLIONS_WHEEL_TRAINSET_{}_{}.csv\".format(superDirName,\n",
        "                                                             yearA,todayString)\n",
        "schemaFilePath = \"{}MegaBall_Schema_{}_as_of_{}.csv\".format(superDirName,yearA, todayString)\n",
        "\n",
        "input_winning_numbers = open(schemaFilePath,\"r+\") #opens winning numbers text file in same directory as script file.\n",
        "# format the file with a comma delimeter, for example: 19,25,29,36,48,12\n",
        "# the first five should be the white numbers and the last (sixth) should be the powerball\n",
        "input_your_numbers = open(wheelFilePath,\"r+\") \n",
        "# opens the text file containing your numbers on your ticket in the same directory as script file.\n",
        "# format the file with a comma delimeter as above, but a semicolon between sets of numbers on the ticket\n",
        "# for example: 19,25,29,36,48,12;5,6,29,35,51,21;34,39,42,44,59,8\n",
        "\n",
        "initial_winning_numbers = input_winning_numbers.read() # reads the text file\n",
        "initial_your_numbers = input_your_numbers.read() # reads the text file\n",
        "\n",
        "winning_numbers = initial_winning_numbers.split(',') #splits the winning numbers into a list\n",
        "#now we will make sure our inputted numbers are actually integers. \n",
        "# it will try what is in try, but if there is an error (or what python calls an exception), \n",
        "# then run the code under except\n",
        "try:    \n",
        "    sanitized_win = []\n",
        "    for number in winning_numbers:\n",
        "        tempwin = int(number)\n",
        "        sanitized_win.append(tempwin)\n",
        "except:\n",
        "    print(\"There seems to be an error with the winning numbers file. Are they numbers?\")\n",
        "    input(\"Press Enter to Exit\")\n",
        "    sys.exit()\n",
        "\n",
        "#this will be how we check our numbers\n",
        "def checknumbers(sanitized_nums):\n",
        "    global sanitized_win\n",
        "    whiteBalls = 0 #will count how many white balls we match\n",
        "    matchPowerBall = False\n",
        "    if sanitized_nums[5] == sanitized_win[5]: #checks winningness of powerball\n",
        "        matchpowerball = True\n",
        "        print(\"You matched the powerball\")\n",
        "    else:\n",
        "        print(\"You did not match the powerball\")\n",
        "    \n",
        "    myNumbers = [sanitized_nums[i] for i in range(0,5,1)]\n",
        "    winWhites = [sanitized_win[i] for i in range(0,5,1)]\n",
        "    for myNum in myNumbers: #will check numbers for matches\n",
        "        for winNum in winWhites:\n",
        "            if myNum == winNum:\n",
        "               whiteBalls += 1\n",
        "    print (\"You matched {} White Balls...\\n\".format(whiteBalls))\n",
        "    #check for prizes\n",
        "    \n",
        "    powerBallPrizes = { \"whiteBalls_by_matchPowerBall\": { \"True\": [4, 4, 7, 100, 50000, \"Jackpot\"], \n",
        "                                                          \"False\": [0, 0, 0, 7, 100, 1000000]  } \n",
        "    }\n",
        "    prize = powerBallPrizes[\"whiteBalls_by_matchPowerBall\"][\"{}\".format(matchPowerBall)][whiteBalls]\n",
        "    return str(prize)\n",
        "\n",
        "separate_tickets = initial_your_numbers.split(';') #splits tickets via the semicolon delimeter\n",
        "\n",
        "ticketCount = 0\n",
        "for ticket in separate_tickets: #run this for each ticket in our list\n",
        "    ticketCount += 1 #will identify our ticket by number\n",
        "    numbers = ticket.split(',') #separates the ticket's numbers\n",
        "    print(f\"Ticket {ticketCount}\")\n",
        "    #this works the same as the try except above, pulling from the list of 'numbers'\n",
        "    try:\n",
        "       sanitizedNums = []\n",
        "       for number in numbers:\n",
        "           tempwin = int(number)\n",
        "           sanitizedNums.append(tempwin)\n",
        "           # this sends the numbers to my check 'function' above and returns the prize amount\n",
        "           ticketprize = checknumbers(sanitizedNums)\n",
        "           print(\"The prize for ticket no. {} is ${}.\\n\".format(ticketCount, ticketprize) )\n",
        "    \n",
        "    except:\n",
        "        print(f\"There seems to be an error with ticket {ticketCount}. Are they numbers?\")\n",
        "    finally:\n",
        "        print(\"\")\n",
        "\n",
        "#closes the files correctly\n",
        "input_winning_numbers.close()\n",
        "input_your_numbers.close()\n",
        "print (\"\"\" Prizes differ in California. See powerball.com for CA prize info. This program and its developer \n",
        "           are not related in any way to Powerball or the Multistate Lottery Association (MUSL). \n",
        "           Numbers not official until verified.\n",
        "       \"\"\")\n",
        "# input(\"Press enter to exit\")"
      ],
      "metadata": {
        "id": "drDcWTf1mJlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Input Validator on Prize Value and Vectorizer Loss / Probability Expectation on Ridge-Regression Model-Type\n",
        "\n",
        "# !pip install sklearn\n",
        "# !pip install scipy\n",
        "# !pip install scikit-learn\n",
        "\n",
        "from sklearn import datasets, linear_model, svm # linear_model.(LinearRegression,LogisticRegression) \n",
        "# Preferential Treatment to LogisticRegression, RidgeRegression (aka KNN-LogRegression) \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler"
      ],
      "metadata": {
        "id": "GnWi3_0Prk9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}